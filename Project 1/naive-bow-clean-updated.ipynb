{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# initialize the Julia file naive-bow\n",
    "using Pkg\n",
    "Pkg.add(\"Knet\")\n",
    "Pkg.add(\"Random\")\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Welcome---\n",
      "|- The constants of the program as follows -|\n",
      "\n",
      "(Train_Test_Size = 25000, Unknown_Tag = \"<unk>\", Sentence_Size = 250, Word_Commonality_Threshold = 0.425)\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_SIZE = 250 # increasing this constant, increases the accuracy value, in most cases.\n",
    "TR_TS_SIZE = 25000\n",
    "UNKNOWN = \"<unk>\"\n",
    "WORD_THRESHOLD = 0.425 # per sentence maximum allowed number\n",
    "\n",
    "EFFECTIVE_RATIO = 0.05 #In order to have an effect, there must be %20 difference in scores among different classes\n",
    "POS_NEG_RATIO = 1.0 # ratio of word occurences in each class (ratio of denominator of laplace smoothing)\n",
    "\n",
    "cleanStr = (s) -> replace(s, r\"[^A-Za-z]\" => \" \")\n",
    "# change this directory wrt test environment\n",
    "#dir = \"/home/minuteman/academics/'19 Fall/NLP/Project-Repo/NLP-Projects/aclImdb_v1/aclImdb/\"\n",
    "\n",
    "datadir = \"aclImdb_v1/aclImdb\"\n",
    "\n",
    "if !isdir(datadir)\n",
    "    download(\n",
    "        \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "        \"aclImdb_v1.tar.gz\",\n",
    "    )\n",
    "    run(`tar xzf aclImdb_v1.tar.gz`)\n",
    "end\n",
    "\n",
    "\n",
    "println(\"---Welcome---\")\n",
    "println(\"|- The constants of the program as follows -|\\n\")\n",
    "println((Train_Test_Size=TR_TS_SIZE,Unknown_Tag=UNKNOWN,Sentence_Size=SENTENCE_SIZE,Word_Commonality_Threshold=WORD_THRESHOLD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readandprep (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readandprep(dir)    \n",
    "    sentences = derive_sents(dir * \"/pos\") # first half is positive / second half is negative\n",
    "    append!(sentences,derive_sents(dir * \"/neg\"))\n",
    "    return sentences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "derive_sents (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function derive_sents(dir)\n",
    "    sentences = []\n",
    "    \n",
    "    for file_dir in readdir(dir)\n",
    "        for line in eachline(dir * \"/\" * file_dir)\n",
    "            sentence = strip(lowercase(line))            \n",
    "            words = split(sentence)\n",
    "            \n",
    "            slash_pos = findfirst(isequal('_'),file_dir)\n",
    "            point_pos = findfirst(isequal('.'),file_dir)\n",
    "            \n",
    "            tag_id = file_dir[slash_pos+1:point_pos-1]\n",
    "            \n",
    "            cleaned_words = []\n",
    "                        \n",
    "            for word in words\n",
    "                cleaned_word = split(cleanStr(word))                \n",
    "                if length(cleaned_word)==0\n",
    "                    continue\n",
    "                end\n",
    "                push!(cleaned_words,first(cleaned_word))\n",
    "            end\n",
    "            sentence = cleaned_words\n",
    "                \n",
    "            if length(sentence) > SENTENCE_SIZE\n",
    "                sentence = sentence[1:SENTENCE_SIZE]\n",
    "            else\n",
    "                while first(size(sentence)) < SENTENCE_SIZE\n",
    "                    push!(sentence, UNKNOWN)\n",
    "                end\n",
    "            end\n",
    "            push!(sentences, (sentence, tag_id))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return sentences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparation for training data ->  9.322294 seconds (85.52 M allocations: 3.708 GiB, 47.02% gc time)\n",
      "Preparation for test data -> 11.544867 seconds (83.26 M allocations: 3.612 GiB, 59.27% gc time)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreparation for training data ->\")\n",
    "@time train_word_tag = readandprep(datadir * \"/train\") # sentences and tags stored here\n",
    "print(\"Preparation for test data ->\")\n",
    "@time test_word_tag = readandprep(datadir * \"/test\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_freq_dicts (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_freq_dicts(sentences)\n",
    "    pos_freq = Dict{String,Float64}()\n",
    "    neg_freq = Dict{String,Float64}()\n",
    "\n",
    "    vocab_freq = Dict{String,Float64}() # To eliminate some too frequent \n",
    "    \n",
    "    # We know positive tagged sentences on the front\n",
    "    focused_dict = pos_freq\n",
    "\n",
    "    class_size = TR_TS_SIZE/2\n",
    "    \n",
    "    for i in 1:TR_TS_SIZE # also equals to size(sentences)\n",
    "        if i == class_size + 1\n",
    "            pos_freq = copy(focused_dict)\n",
    "            focused_dict = copy(neg_freq)\n",
    "        end\n",
    "        words, tag = sentences[i]\n",
    "        tag_weight = ceil(abs(5.5 - parse(Int64,tag))) # Severeness of the comment\n",
    "        \n",
    "        #previous_words = [] # only one occurence would be enough\n",
    "        \n",
    "        for word in words\n",
    "            vocab_freq[word] = get!(vocab_freq, word, 0) + 1\n",
    "            #word in previous_words && continue\n",
    "           \n",
    "            if word != UNKNOWN\n",
    "                word_val = get!(focused_dict, word, 0)\n",
    "                focused_dict[word] = word_val + tag_weight # add tag_weight\n",
    "                #push!(previous_words,word)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    neg_freq = focused_dict\n",
    "    \n",
    "    freq_dicts = (pos_freq,neg_freq)    \n",
    "    del_words = []\n",
    "    freq_words = []\n",
    "    \n",
    "    for word in keys(pos_freq)\n",
    "        !(word in keys(neg_freq)) && continue\n",
    "        pos_val = pos_freq[word]\n",
    "        neg_val = neg_freq[word]\n",
    "        \n",
    "        # If there is quite less difference, no need to have the word\n",
    "        if (abs(pos_val-neg_val)<(min(pos_val,neg_val)*EFFECTIVE_RATIO))\n",
    "            delete_from_both(pos_freq,neg_freq,word)\n",
    "            push!(del_words,word)\n",
    "        end\n",
    "        \n",
    "        if vocab_freq[word] >= WORD_THRESHOLD*TR_TS_SIZE\n",
    "            delete_from_both(pos_freq,neg_freq,word)\n",
    "            push!(freq_words,word)\n",
    "        end\n",
    "            \n",
    "    end\n",
    "    \n",
    "    # number of occurences in each class would change possibilities\n",
    "    total_pos = sum(values(pos_freq)) \n",
    "    total_neg = sum(values(neg_freq))\n",
    "    total = total_pos + total_neg + 1 # laplace denum\n",
    "    \n",
    "    global POS_NEG_RATIO = (total_neg + total) / (total_pos + total) \n",
    "\n",
    "    return freq_dicts,del_words,freq_words\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_from_both (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function delete_from_both(pos_freq,neg_freq,word)\n",
    "    delete!(pos_freq,word)\n",
    "    delete!(neg_freq,word)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparation for vocabulary ->\n",
      " 10.450767 seconds (105.82 M allocations: 3.285 GiB, 24.73% gc time)\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nPreparation for vocabulary ->\")\n",
    "@time freq_dicts,del_words,freq_words = get_freq_dicts(train_word_tag);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_a_sent (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function score_a_sent(sentence,freq;exact=false)\n",
    "    pos_ratio = 1.0\n",
    "        \n",
    "    for word in sentence\n",
    "        pos_ratio *= score_word(word,freq)\n",
    "    end\n",
    "    \n",
    "    exact && return pos_ratio \n",
    "    return pos_ratio>=1 # true for positive, false for negative\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_word (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function score_word(word,freq)\n",
    "    pos_freq,neg_freq = freq\n",
    "    \n",
    "    pos_score = get(pos_freq, word, 0) + 1 # Laplace Smoothing\n",
    "    neg_score = get(neg_freq, word, 0) + 1\n",
    "          \n",
    "    return POS_NEG_RATIO*pos_score/neg_score\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagclassifier (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predall(comment_tag_set,freq)\n",
    "    store = []\n",
    "    correct = 0\n",
    "    for i = 1:TR_TS_SIZE\n",
    "        sentence, tag = comment_tag_set[i]\n",
    "        if (score_a_sent(sentence,freq) == tagclassifier(tag))\n",
    "            correct += 1\n",
    "        else \n",
    "            push!(store,comment_tag_set[i])\n",
    "        end\n",
    "    end\n",
    "    return correct * 1.0 / TR_TS_SIZE,store\n",
    "end\n",
    "\n",
    "function tagclassifier(tag)\n",
    "    return parse(Int64, tag) > 5 # a tag > 5 is a positive comment\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction for train->\n",
      "  2.309965 seconds (36.03 M allocations: 938.896 MiB, 4.82% gc time)\n",
      "Prediction for test->\n",
      "  2.091269 seconds (35.54 M allocations: 919.936 MiB, 4.72% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.92528, 0.82516)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"\\nPrediction for train->\")\n",
    "@time acc_trn,wrongs_trn = predall(train_word_tag,freq_dicts)\n",
    "\n",
    "println(\"Prediction for test->\")\n",
    "@time acc_tst,wrongs_tst = predall(test_word_tag,freq_dicts)\n",
    "\n",
    "\n",
    "acc_trn,acc_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
