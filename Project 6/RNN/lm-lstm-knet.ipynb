{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import Pkg\n",
    "using Pkg; for p in (\"Knet\",\"IterTools\",\"WordTokenizers\",\"Test\",\"Random\",\"Statistics\",\"Dates\",\"LinearAlgebra\",\"CuArrays\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "using Statistics, IterTools, WordTokenizers, Test, Knet, Random, Dates, Base.Iterators, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8000000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pkg.add(\"CuArrays\")\n",
    "using CuArrays\n",
    "using CuArrays: CuArrays, usage_limit\n",
    "CuArrays.usage_limit[] = 8_000_000_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "Package name: Statistics Version: 0.0.1\n",
      "Package name: Test Version: 0.0.1\n",
      "Package name: Random Version: 0.0.1\n",
      "Package name: Atom Version: 0.11.3\n",
      "Package name: JLD Version: 0.9.1\n",
      "Package name: Suppressor Version: 0.1.1\n",
      "Package name: WordTokenizers Version: 0.5.3\n",
      "Package name: Juno Version: 0.7.2\n",
      "Package name: AutoGrad Version: 1.2.0\n",
      "Package name: IterTools Version: 1.3.0\n",
      "Package name: Literate Version: 2.2.1\n",
      "Package name: LinearAlgebra Version: 0.0.1\n",
      "Package name: CUDAapi Version: 2.0.0\n",
      "Package name: StatsBase Version: 0.32.0\n",
      "Package name: HDF5 Version: 0.12.5\n",
      "Package name: CuArrays Version: 1.5.0\n",
      "Package name: IJulia Version: 1.20.2\n",
      "Package name: Dates Version: 0.0.1\n",
      "Package name: Knet Version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "# Update and list all packages\n",
    "Pkg.update()\n",
    "pkgs = Pkg.installed()\n",
    "\n",
    "for package in keys(pkgs)\n",
    "    if pkgs[package] == nothing\n",
    "        pkgs[package] = VersionNumber(\"0.0.1\")\n",
    "    end\n",
    "    println(\"Package name: \", package, \" Version: \", pkgs[package])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.atype() = KnetArray{Float32} \n",
    "is_lstm_strategy_on = false # if true rnn type becomes lstm, otherwise we preferred to use relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary Structure\n",
    "struct Vocab\n",
    "    w2i::Dict{String,Int}\n",
    "    i2w::Vector{String}\n",
    "    unk::Int\n",
    "    eos::Int\n",
    "    tokenizer\n",
    "end\n",
    "\n",
    "function Vocab(file::String; tokenizer=split, vocabsize=Inf, mincount=1, unk=\"<unk>\", eos=\"<s>\")\n",
    "    vocab_freq = Dict{String,Int64}(unk => 1, eos => 1)\n",
    "    w2i = Dict{String, Int64}(unk => 2, eos => 1)\n",
    "    i2w = Vector{String}()\n",
    "\n",
    "    push!(i2w, eos)\n",
    "    push!(i2w, unk)\n",
    "\n",
    "    open(file) do f\n",
    "        for line in eachline(f)\n",
    "            sentence = strip(lowercase(line))\n",
    "            sentence = tokenizer(line, [' '], keepempty = false)\n",
    "\n",
    "            for word in sentence\n",
    "                word == unk && continue\n",
    "                word == eos && continue # They are default ones to be added later\n",
    "                vocab_freq[word] = get!(vocab_freq, word, 0) + 1\n",
    "            end\n",
    "        end\n",
    "        close(f)\n",
    "    end\n",
    "\n",
    "\n",
    "    # End of vanilla implementation of the vocaulary\n",
    "    # From here we must add the mincount and vocabsize properties\n",
    "    # We must change the first two property of the vocab wrt those paramaters\n",
    "    vocab_freq = sort!(\n",
    "        collect(vocab_freq),\n",
    "        by = tuple -> last(tuple),\n",
    "        rev = true,\n",
    "    )\n",
    "\n",
    "    if length(vocab_freq)>vocabsize - 2 # eos and unk ones\n",
    "        vocab_freq = vocab_freq[1:vocabsize-2] # trim to fit the size\n",
    "    end\n",
    "\n",
    "    #vocab_freq = reverse(vocab_freq)\n",
    "\n",
    "    while true\n",
    "        length(vocab_freq)==0 && break\n",
    "        word,freq = vocab_freq[end]\n",
    "        freq>=mincount && break # since it is already ordered\n",
    "        vocab_freq = vocab_freq[1:(end - 1)]\n",
    "    end\n",
    "    #pushfirst!(vocab_freq,unk=>1,eos=>1) # freq does not matter, just adding the\n",
    "    for i in 1:length(vocab_freq)\n",
    "        word, freq = vocab_freq[i]\n",
    "        ind = (get!(w2i, word, 1+length(w2i)))\n",
    "        (length(i2w) < ind) && push!(i2w, word)\n",
    "    end\n",
    "\n",
    "    return Vocab(w2i, i2w, 2, 1, tokenizer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special reader for the task\n",
    "struct TextReader\n",
    "    file::String\n",
    "    vocab::Vocab\n",
    "end\n",
    "\n",
    "word2ind(dict,x) = get(dict, x, 2)\n",
    "\n",
    "#Implementing the iterate function\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    if s == nothing\n",
    "        state = open(r.file)\n",
    "        Base.iterate(r,state)\n",
    "    else\n",
    "        if eof(s) == true\n",
    "            close(s)\n",
    "            return nothing\n",
    "        else\n",
    "            line = readline(s)\n",
    "            line = strip(lowercase(line))\n",
    "            sent = r.vocab.tokenizer(line, [' '], keepempty = false)\n",
    "            sent_ind = Int[]\n",
    "            for word in sent\n",
    "                ind = word2ind(r.vocab.w2i,word)\n",
    "                push!(sent_ind,ind)\n",
    "            end\n",
    "            push!(sent_ind,r.vocab.eos)\n",
    "            return (sent_ind, s)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextReader(\"nn4nlp-code/data/ptb/valid.txt\", Vocab(Dict(\"adviser\" => 1750,\"enjoy\" => 4607,\"advertisements\" => 7826,\"fight\" => 1441,\"nicholas\" => 3783,\"everywhere\" => 6278,\"surveyed\" => 3556,\"helping\" => 2081,\"whose\" => 621,\"manufacture\" => 5052…), [\"<s>\", \"<unk>\", \"the\", \"N\", \"of\", \"to\", \"a\", \"in\", \"and\", \"'s\"  …  \"cluett\", \"hydro-quebec\", \"memotec\", \"photography\", \"ipo\", \"ssangyong\", \"fromstein\", \"ferc\", \"gitano\", \"daewoo\"], 2, 1, split))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File \n",
    "const datadir = \"nn4nlp-code/data/ptb\"\n",
    "isdir(datadir) || run(`git clone https://github.com/neubig/nn4nlp-code.git`)\n",
    "\n",
    "if !isdefined(Main, :vocab)\n",
    "    vocab = Vocab(\"$datadir/train.txt\", mincount=1)\n",
    "\n",
    "    train = TextReader(\"$datadir/train.txt\", vocab)\n",
    "    test = TextReader(\"$datadir/valid.txt\", vocab)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed\n",
    "struct Embed; w; end\n",
    "\n",
    "function Embed(vocabsize::Int, embedsize::Int)\n",
    "    Embed(param(embedsize,vocabsize))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    l.w[:,x]\n",
    "end\n",
    "\n",
    "#Linear\n",
    "struct Linear; w; b; end\n",
    "\n",
    "function Linear(inputsize::Int, outputsize::Int)\n",
    "    Linear(param(outputsize,inputsize), param0(outputsize))\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    l.w * mat(x,dims=1) .+ l.b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask!\n",
    "function mask!(a,pad)\n",
    "    matr = a\n",
    "    for j in 1:size(matr)[1]\n",
    "        i=0\n",
    "        while i<(length(matr[j,:])-1)\n",
    "            matr[j,length(matr[j,:])-i-1]!=pad && break\n",
    "\n",
    "            if matr[j,length(matr[j,:])-i]== pad\n",
    "                matr[j,length(matr[j,:])-i]= 0\n",
    "            end\n",
    "            i+=1\n",
    "        end\n",
    "    end\n",
    "    matr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching\n",
    "struct LMData\n",
    "    src::TextReader\n",
    "    batchsize::Int\n",
    "    maxlength::Int\n",
    "    bucketwidth::Int\n",
    "    buckets\n",
    "end\n",
    "\n",
    "function LMData(src::TextReader; batchsize = 64, maxlength = typemax(Int), bucketwidth = 10)\n",
    "    numbuckets = min(128, maxlength ÷ bucketwidth)\n",
    "    buckets = [ [] for i in 1:numbuckets ]\n",
    "    LMData(src, batchsize, maxlength, bucketwidth, buckets)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{LMData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{LMData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{LMData}) = Matrix{Int}\n",
    "\n",
    "function Base.iterate(d::LMData, state=nothing)\n",
    "    if state == nothing\n",
    "        for b in d.buckets; empty!(b); end\n",
    "    end\n",
    "    bucket,ibucket = nothing,nothing\n",
    "    while true\n",
    "        iter = (state === nothing ? iterate(d.src) : iterate(d.src, state))\n",
    "        if iter === nothing\n",
    "            ibucket = findfirst(x -> !isempty(x), d.buckets)\n",
    "            bucket = (ibucket === nothing ? nothing : d.buckets[ibucket])\n",
    "            break\n",
    "        else\n",
    "            sent, state = iter\n",
    "            if length(sent) > d.maxlength || length(sent) == 0; continue; end\n",
    "            ibucket = min(1 + (length(sent)-1) ÷ d.bucketwidth, length(d.buckets))\n",
    "            bucket = d.buckets[ibucket]\n",
    "            push!(bucket, sent)\n",
    "            if length(bucket) === d.batchsize; break; end\n",
    "        end\n",
    "    end\n",
    "    if bucket === nothing; return nothing; end\n",
    "    batchsize = length(bucket)\n",
    "    maxlen = maximum(length.(bucket))\n",
    "    batch = fill(d.src.vocab.eos, batchsize, maxlen + 1)\n",
    "    for i in 1:batchsize\n",
    "        batch[i, 1:length(bucket[i])] = bucket[i]\n",
    "    end\n",
    "    empty!(bucket)\n",
    "    return batch, state\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_model"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct RNN_model\n",
    "    embed::Embed        # language embedding\n",
    "    rnn::RNN            # RNN (can be bidirectional)\n",
    "    projection::Linear  # converts output to vocab scores\n",
    "    dropout::Real       # dropout probability to prevent overfitting\n",
    "    vocab::Vocab        # language vocabulary  \n",
    "end\n",
    "\n",
    "function RNN_model(hidden::Int,      # hidden size for both the encoder and decoder RNN\n",
    "                embsz::Int,          # embedding size\n",
    "                vocab::Vocab;     # vocabulary for source language\n",
    "                layers=1,            # number of layers\n",
    "                bidirectional=false, # whether encoder RNN is bidirectional\n",
    "                dropout=0)           # dropout probability\n",
    "\n",
    "    embed = Embed(length(vocab.i2w),embsz)\n",
    "\n",
    "    rnn = RNN(embsz,hidden;rnnType=is_lstm_strategy_on ? :lstm : :relu, numLayers=layers,bidirectional=bidirectional ,dropout= dropout)\n",
    "    \n",
    "    layerMultiplier = bidirectional ? 2 : 1\n",
    "    \n",
    "    projection = Linear(layerMultiplier*hidden,length(vocab.i2w))\n",
    "\n",
    "    RNN_model(embed,rnn,projection,dropout,vocab)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calc_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_scores(rm::RNN_model, data; average=true)\n",
    "    B, Tx = size(data)\n",
    "    \n",
    "    project = rm.projection\n",
    "    emb = rm.embed(data)\n",
    "    \n",
    "    rm.rnn.h = 0\n",
    "    rm.rnn.c = 0\n",
    "\n",
    "    y = rm.rnn(emb)\n",
    "\n",
    "    return project(reshape(y,:,B*Tx))\n",
    "    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_f (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_f(model, batch; average = true)  \n",
    "    verify = deepcopy(batch[:,2:end])\n",
    "    mask!(verify,vocab.eos)\n",
    "        \n",
    "    scores = calc_scores(model,batch[:,1:end-1]) # trim one end\n",
    "   \n",
    "    return nll(scores,verify;average=average)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maploss (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function maploss(lossfn, model, data; average = true)\n",
    "    total_words = 0\n",
    "    total_loss = 0\n",
    "    for part in collect(data)\n",
    "        curr_loss, curr_word = lossfn(model,part, average = false)\n",
    "        total_loss += curr_loss\n",
    "        total_words += curr_word\n",
    "    end\n",
    "\n",
    "    average && return total_loss/total_words\n",
    "    return total_loss, total_words\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_model(Embed(P(KnetArray{Float32,2}(512,10000))), RNNRELU(input=512,hidden=512,bidirectional,dropout=0.2), Linear(P(KnetArray{Float32,2}(10000,1024)), P(KnetArray{Float32,1}(10000))), 0.2, Vocab(Dict(\"adviser\" => 1750,\"enjoy\" => 4607,\"advertisements\" => 7826,\"fight\" => 1441,\"nicholas\" => 3783,\"everywhere\" => 6278,\"surveyed\" => 3556,\"helping\" => 2081,\"whose\" => 621,\"manufacture\" => 5052…), [\"<s>\", \"<unk>\", \"the\", \"N\", \"of\", \"to\", \"a\", \"in\", \"and\", \"'s\"  …  \"cluett\", \"hydro-quebec\", \"memotec\", \"photography\", \"ipo\", \"ssangyong\", \"fromstein\", \"ferc\", \"gitano\", \"daewoo\"], 2, 1, split))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN_model(512, 512, vocab; bidirectional=true, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Array{Array{Int64,2},1}:\n",
       " [9236 2 … 1 1; 24 2 … 1 1; … ; 70 169 … 1 1; 2996 2814 … 1 1]   \n",
       " [9974 9990 … 1 1; 7512 2 … 1 1; … ; 1206 84 … 1 1; 65 144 … 1 1]\n",
       " [3 475 … 1 1; 70 41 … 1 1; … ; 145 194 … 1 1; 9 3 … 1 1]        \n",
       " [3 2531 … 1 1; 3 964 … 1 1; … ; 671 3 … 1 1; 3363 9767 … 1 1]   \n",
       " [7 949 … 1 1; 368 1970 … 1 1; … ; 8 515 … 1 1; 15 10 … 1 1]     \n",
       " [142 2650 … 1 1; 9 98 … 1 1; … ; 58 5 … 1 1; 24 2 … 1 1]        \n",
       " [67 64 … 1 1; 8 7 … 1 1; … ; 6622 2 … 1 1; 2 18 … 1 1]          \n",
       " [7 2 … 1 1; 84 14 … 1 1; … ; 57 10 … 1 1; 57 10 … 1 1]          \n",
       " [486 2 … 1 1; 46 9 … 1 1; … ; 30 166 … 1 1; 673 8 … 1 1]        \n",
       " [24 1184 … 1 1; 29 25 … 1 1; … ; 6 3 … 1 1; 3 2 … 1 1]          \n",
       " [3 1287 … 1 1; 8 2309 … 1 1; … ; 638 2 … 1 1; 17 3 … 1 1]       \n",
       " [30 1152 … 1 1; 8 3430 … 1 1; … ; 3 4145 … 1 1; 75 2657 … 1 1]  \n",
       " [3 465 … 1 1; 2 8 … 1 1; … ; 19 50 … 1 1; 24 8222 … 1 1]        \n",
       " ⋮                                                               \n",
       " [45 3 … 1 1; 2270 6 … 1 1; … ; 65 276 … 1 1; 8 2 … 1 1]         \n",
       " [3 130 … 1 1; 490 1240 … 1 1; … ; 5041 2 … 1 1; 9 3 … 1 1]      \n",
       " [89 353 … 1 1; 111 575 … 1 1; … ; 111 564 … 1 1; 84 10 … 1 1]   \n",
       " [213 28 … 1 1; 2 2 … 1 1; … ; 5685 14 … 1 1; 137 47 … 1 1]      \n",
       " [60 8 … 1 1; 29 873 … 1 1; … ; 91 374 … 1 1; 480 143 … 1 1]     \n",
       " [261 67 … 1 1; 3 265 … 1 1; … ; 30 3 … 1 1; 3 1127 … 1 1]       \n",
       " [330 322 … 1 1; 3 742 … 1 1; … ; 32 1931 … 1 1; 60 46 … 1 1]    \n",
       " [65 90 … 1 1; 21 3 … 1 1; … ; 9 2 … 1 1; 8 522 … 1 1]           \n",
       " [3 48 … 1 1; 30 69 … 1 1; … ; 3907 1956 … 1 1; 9522 249 … 1 1]  \n",
       " [8 522 … 1 1; 8 522 … 1 1; … ; 24 6644 … 1 1; 8 36 … 1 1]       \n",
       " [87 2 … 1 1; 3 2912 … 1 1; … ; 24 4553 … 1 1; 29 284 … 1 1]     \n",
       " [15 743 … 1 1; 487 3 … 1 1; … ; 215 6 … 1 1; 125 520 … 1 1]     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches = collect(LMData(train))\n",
    "test_batches = collect(LMData(test))\n",
    "train_batches50 = train_batches[1:50] # Small sample for quick loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RNN_model(Embed(P(KnetArray{Float32,2}(512,10000))), RNNRELU(input=512,hidden=512,bidirectional,dropout=0.2), Linear(P(KnetArray{Float32,2}(10000,1024)), P(KnetArray{Float32,1}(10000))), 0.2, Vocab(Dict(\"adviser\" => 1750,\"enjoy\" => 4607,\"advertisements\" => 7826,\"fight\" => 1441,\"nicholas\" => 3783,\"everywhere\" => 6278,\"surveyed\" => 3556,\"helping\" => 2081,\"whose\" => 621,\"manufacture\" => 5052…), [\"<s>\", \"<unk>\", \"the\", \"N\", \"of\", \"to\", \"a\", \"in\", \"and\", \"'s\"  …  \"cluett\", \"hydro-quebec\", \"memotec\", \"photography\", \"ipo\", \"ssangyong\", \"fromstein\", \"ferc\", \"gitano\", \"daewoo\"], 2, 1, split)), 9.210459f0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = adam(loss_f, ((model, batch) for batch in train_batches))\n",
    "bestmodel, bestloss = deepcopy(model), maploss(loss_f, model, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣▎                   ┫ [1.45%, 958/66200, 07:37/08:46:25, 1.73i/s] (trn = 2.3684053f0, dev = 2.6416502f0, ∇ = 1.803042f0)))"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] macro expansion at /home/minuteman/.julia/packages/CUDAdrv/3EzC1/src/error.jl:17 [inlined]",
      " [2] cuMemAlloc_v2(::Base.RefValue{CUDAdrv.CuPtr{Nothing}}, ::Int64) at /home/minuteman/.julia/packages/CUDAdrv/3EzC1/src/libcuda.jl:312",
      " [3] alloc at /home/minuteman/.julia/packages/CUDAdrv/3EzC1/src/memory.jl:64 [inlined]",
      " [4] macro expansion at /home/minuteman/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]",
      " [5] macro expansion at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory.jl:55 [inlined]",
      " [6] macro expansion at ./util.jl:213 [inlined]",
      " [7] actual_alloc(::Int64) at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory.jl:54",
      " [8] actual_alloc at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory/binned.jl:55 [inlined]",
      " [9] macro expansion at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory/binned.jl:198 [inlined]",
      " [10] macro expansion at /home/minuteman/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]",
      " [11] pool_alloc(::Int64, ::Int64) at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory/binned.jl:197",
      " [12] (::getfield(CuArrays.BinnedPool, Symbol(\"##12#13\")){Int64,Int64,Set{CuArrays.BinnedPool.Block},Array{CuArrays.BinnedPool.Block,1}})() at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory/binned.jl:293",
      " [13] lock(::getfield(CuArrays.BinnedPool, Symbol(\"##12#13\")){Int64,Int64,Set{CuArrays.BinnedPool.Block},Array{CuArrays.BinnedPool.Block,1}}, ::ReentrantLock) at ./lock.jl:140",
      " [14] alloc(::Int64) at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory/binned.jl:292",
      " [15] macro expansion at /home/minuteman/.julia/packages/TimerOutputs/7Id5J/src/TimerOutput.jl:228 [inlined]",
      " [16] macro expansion at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory.jl:135 [inlined]",
      " [17] macro expansion at ./util.jl:213 [inlined]",
      " [18] alloc at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/memory.jl:134 [inlined]",
      " [19] CuArray{UInt8,1,P} where P(::UndefInitializer, ::Tuple{Int64}) at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/array.jl:90",
      " [20] Type at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/array.jl:98 [inlined]",
      " [21] Type at /home/minuteman/.julia/packages/CuArrays/ZYCpV/src/array.jl:99 [inlined]",
      " [22] KnetPtrCu(::Int64) at /home/minuteman/.julia/packages/Knet/LjPts/src/cuarray.jl:90",
      " [23] Type at /home/minuteman/.julia/packages/Knet/LjPts/src/kptr.jl:102 [inlined]",
      " [24] Type at /home/minuteman/.julia/packages/Knet/LjPts/src/karray.jl:82 [inlined]",
      " [25] similar at /home/minuteman/.julia/packages/Knet/LjPts/src/karray.jl:164 [inlined]",
      " [26] similar at /home/minuteman/.julia/packages/Knet/LjPts/src/karray.jl:167 [inlined]",
      " [27] dropback(::KnetArray{Float32,3}, ::KnetArray{Float32,3}, ::KnetArray{Float32,3}, ::Float64) at /home/minuteman/.julia/packages/Knet/LjPts/src/dropout.jl:41",
      " [28] #back#781 at ./none:0 [inlined]",
      " [29] (::getfield(AutoGrad, Symbol(\"#kw##back\")))(::NamedTuple{(:seed, :drop),Tuple{Int64,Bool}}, ::typeof(AutoGrad.back), ::typeof(dropout), ::Type{AutoGrad.Arg{1}}, ::KnetArray{Float32,3}, ::AutoGrad.Result{KnetArray{Float32,3}}, ::AutoGrad.Result{KnetArray{Float32,3}}, ::Float64) at ./none:0",
      " [30] #differentiate#3(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::typeof(AutoGrad.differentiate), ::Function) at /home/minuteman/.julia/packages/AutoGrad/pTNVv/src/core.jl:165",
      " [31] differentiate at /home/minuteman/.julia/packages/AutoGrad/pTNVv/src/core.jl:135 [inlined]",
      " [32] (::getfield(Main, Symbol(\"##25#28\")))(::Knet.Progress{IterTools.NCycle{Knet.Minimize{Base.Generator{Array{Array{Int64,2},1},getfield(Main, Symbol(\"##23#24\"))}}}}) at ./In[21]:4",
      " [33] progressbar(::Knet.Progress{IterTools.NCycle{Knet.Minimize{Base.Generator{Array{Array{Int64,2},1},getfield(Main, Symbol(\"##23#24\"))}}}}, ::Tuple{Float32,Tuple{Int64,Int64}}) at /home/minuteman/.julia/packages/Knet/LjPts/src/progress.jl:84",
      " [34] iterate(::Knet.Progress{IterTools.NCycle{Knet.Minimize{Base.Generator{Array{Array{Int64,2},1},getfield(Main, Symbol(\"##23#24\"))}}}}, ::Tuple{Int64,Int64}) at /home/minuteman/.julia/packages/Knet/LjPts/src/progress.jl:78",
      " [35] #progress!#692(::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:seconds,),Tuple{Int64}}}, ::typeof(progress!), ::Function, ::Vararg{Any,N} where N) at /home/minuteman/.julia/packages/Knet/LjPts/src/progress.jl:58",
      " [36] (::getfield(Knet, Symbol(\"#kw##progress!\")))(::NamedTuple{(:seconds,),Tuple{Int64}}, ::typeof(progress!), ::Function, ::Vararg{Any,N} where N) at ./none:0",
      " [37] top-level scope at In[21]:1"
     ]
    }
   ],
   "source": [
    "progress!(ncycle(epoch, 100), seconds=5) do x\n",
    "    global bestmodel, bestloss\n",
    "    ## Report gradient norm for the first batch\n",
    "    f = @diff loss_f(model,train_batches[1])\n",
    "    gnorm = sqrt(sum(norm(grad(f,x))^2 for x in params(model)))\n",
    "    ## Report training and validation loss\n",
    "    trnloss = maploss(loss_f,model, train_batches50)\n",
    "    devloss = maploss(loss_f,model, test_batches)\n",
    "    ## Save model that does best on validation data\n",
    "    if devloss < bestloss\n",
    "        bestmodel, bestloss = deepcopy(model), devloss\n",
    "    end\n",
    "    (trn=exp(trnloss), dev=exp(devloss), ∇=gnorm)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
