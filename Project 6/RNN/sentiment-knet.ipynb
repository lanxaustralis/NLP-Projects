{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import Pkg\n",
    "using Pkg; for p in (\"Knet\",\"IterTools\",\"WordTokenizers\",\"Test\",\"Random\",\"Statistics\",\"Dates\",\"LinearAlgebra\",\"CuArrays\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "using Statistics, IterTools, WordTokenizers, Test, Knet, Random, Dates, Base.Iterators, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "Package name: Statistics Version: 0.0.1\n",
      "Package name: Test Version: 0.0.1\n",
      "Package name: Random Version: 0.0.1\n",
      "Package name: WordTokenizers Version: 0.5.3\n",
      "Package name: AutoGrad Version: 1.2.0\n",
      "Package name: IterTools Version: 1.3.0\n",
      "Package name: LinearAlgebra Version: 0.0.1\n",
      "Package name: StatsBase Version: 0.32.0\n",
      "Package name: CuArrays Version: 1.5.0\n",
      "Package name: IJulia Version: 1.20.2\n",
      "Package name: Dates Version: 0.0.1\n",
      "Package name: Knet Version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "# Update and list all packages\n",
    "Pkg.update()\n",
    "pkgs = Pkg.installed()\n",
    "\n",
    "for package in keys(pkgs)\n",
    "    if pkgs[package] == nothing\n",
    "        pkgs[package] = VersionNumber(\"0.0.1\")\n",
    "    end\n",
    "    println(\"Package name: \", package, \" Version: \", pkgs[package])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CuArrays: CuArrays, usage_limit\n",
    "CuArrays.usage_limit[] = 8_000_000_000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "Knet.atype() = KnetArray{Float32} #Array{Float32}\n",
    "is_lstm_strategy_on = true # if true rnn type becomes lstm, otherwise we preferred to use relu\n",
    "gpu() # GPU test must result as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary Structure\n",
    "struct Vocab\n",
    "    w2i::Dict{String,Int}\n",
    "    i2w::Vector{String}\n",
    "    tags::Vector{String}\n",
    "    unk::Int\n",
    "    eos::Int\n",
    "    tokenizer    \n",
    "end\n",
    "\n",
    "function Vocab(file::String; tokenizer=split, vocabsize=Inf, mincount=1, unk=\"<unk>\", eos=\"<s>\")\n",
    "    vocab_freq = Dict{String,Int64}(unk => 0, eos => 0)\n",
    "    w2i = Dict{String, Int64}(unk => 2, eos => 1)\n",
    "    i2w = Vector{String}()\n",
    "    tags = Vector{String}()\n",
    "\n",
    "    push!(i2w, eos)\n",
    "    push!(i2w, unk)\n",
    "        \n",
    "    open(file) do f\n",
    "        for line in eachline(f)\n",
    "            tag, sentence = split(strip(lowercase(line)),\" ||| \")\n",
    "            !(tag in tags) && push!(tags, tag)\n",
    "            \n",
    "            sentence = tokenizer(sentence, [' '], keepempty = false)\n",
    "            \n",
    "            for word in sentence\n",
    "                word == unk && continue\n",
    "                word == eos && continue # They are default ones to be added later\n",
    "                vocab_freq[word] = get!(vocab_freq, word, 0) + 1\n",
    "            end\n",
    "        end\n",
    "        close(f)\n",
    "    end\n",
    "\n",
    "\n",
    "    # End of vanilla implementation of the vocabulary\n",
    "    # From here we must add the mincount and vocabsize properties\n",
    "    # We must change the first two property of the vocab wrt those paramaters\n",
    "    vocab_freq = sort!(\n",
    "        collect(vocab_freq),\n",
    "        by = tuple -> last(tuple),\n",
    "        rev = true,\n",
    "    )\n",
    "\n",
    "    if length(vocab_freq)>vocabsize - 2 # eos and unk ones\n",
    "        vocab_freq = vocab_freq[1:vocabsize-2] # trim to fit the size\n",
    "    end\n",
    "\n",
    "    #vocab_freq = reverse(vocab_freq)\n",
    "\n",
    "    while true\n",
    "        length(vocab_freq)==0 && break\n",
    "        word,freq = vocab_freq[end]\n",
    "        freq>=mincount && break # since it is already ordered\n",
    "        vocab_freq = vocab_freq[1:(end - 1)]\n",
    "    end\n",
    "    #pushfirst!(vocab_freq,unk=>1,eos=>1) # freq does not matter, just adding the\n",
    "    for i in 1:length(vocab_freq)\n",
    "        word, freq = vocab_freq[i]\n",
    "        ind = (get!(w2i, word, 1+length(w2i)))\n",
    "        (length(i2w) < ind) && push!(i2w, word)\n",
    "    end\n",
    "\n",
    "    return Vocab(w2i, i2w, tags, 2, 1, tokenizer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special reader for the task\n",
    "struct TextReader\n",
    "    file::String\n",
    "    vocab::Vocab\n",
    "end\n",
    "\n",
    "word2ind(dict,x) = get(dict, x, 2)\n",
    "findtagid(tag,vector) = findall(x -> x == tag,vector)[1]\n",
    "\n",
    "#Implementing the iterate function\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    if s == nothing\n",
    "        state = open(r.file)\n",
    "        Base.iterate(r,state)\n",
    "    else\n",
    "        if eof(s) == true\n",
    "            close(s)\n",
    "            return nothing\n",
    "        else\n",
    "            line = readline(s)\n",
    "            sent_ind = Int[]\n",
    "            \n",
    "            # Tagification\n",
    "            tag, sentence = split(strip(lowercase(line)),\" ||| \")\n",
    "            \n",
    "            tagind = findtagid(tag,r.vocab.tags)\n",
    "            push!(sent_ind,tagind)\n",
    "            \n",
    "            sent = r.vocab.tokenizer(strip(lowercase(sentence)), [' '], keepempty = false)\n",
    "            \n",
    "            for word in sent\n",
    "                ind = word2ind(r.vocab.w2i,word)\n",
    "                push!(sent_ind,ind)\n",
    "            end\n",
    "            push!(sent_ind,r.vocab.eos)\n",
    "            return (sent_ind, s)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextReader(\"nn4nlp-code/data/classes/test.txt\", Vocab(Dict(\"aimlessly\" => 4907,\"offend\" => 3845,\"enjoy\" => 435,\"chocolate\" => 4908,\"fight\" => 1823,\"nicholas\" => 1775,\"everywhere\" => 4593,\"princess\" => 7582,\"uniformly\" => 3846,\"larky\" => 6921…), [\"<s>\", \"<unk>\", \".\", \"the\", \",\", \"a\", \"and\", \"of\", \"to\", \"is\"  …  \"scarifying\", \"sealed\", \"effectiveness\", \"wraps\", \"na\", \"wills\", \"circles\", \"sharper\", \"pluto\", \"pleaser\"], [\"3\", \"4\", \"2\", \"1\", \"0\"], 2, 1, split))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File \n",
    "const datadir = \"nn4nlp-code/data/classes\"\n",
    "isdir(datadir) || run(`git clone https://github.com/neubig/nn4nlp-code.git`)\n",
    "\n",
    "if !isdefined(Main, :a_vocab)\n",
    "    vocab = Vocab(\"$datadir/train.txt\", mincount=2)\n",
    "\n",
    "    train = TextReader(\"$datadir/train.txt\", vocab)\n",
    "    test = TextReader(\"$datadir/test.txt\", vocab)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatching\n",
    "struct LMData\n",
    "    src::TextReader\n",
    "    batchsize::Int\n",
    "    maxlength::Int\n",
    "    bucketwidth::Int\n",
    "    buckets\n",
    "end\n",
    "\n",
    "function LMData(src::TextReader; batchsize = BATCH_SIZE, maxlength = typemax(Int), bucketwidth = 10)\n",
    "    numbuckets = min(128, maxlength ÷ bucketwidth)\n",
    "    buckets = [ [] for i in 1:numbuckets ]\n",
    "    LMData(src, batchsize, maxlength, bucketwidth, buckets)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{LMData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{LMData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{LMData}) = Matrix{Int}\n",
    "\n",
    "function Base.iterate(d::LMData, state=nothing)\n",
    "    if state == nothing\n",
    "        for b in d.buckets; empty!(b); end\n",
    "    end\n",
    "    bucket,ibucket = nothing,nothing\n",
    "    while true\n",
    "        iter = (state === nothing ? iterate(d.src) : iterate(d.src, state))\n",
    "        if iter === nothing\n",
    "            ibucket = findfirst(x -> !isempty(x), d.buckets)\n",
    "            bucket = (ibucket === nothing ? nothing : d.buckets[ibucket])\n",
    "            break\n",
    "        else\n",
    "            sent, state = iter\n",
    "            if length(sent) > d.maxlength || length(sent) == 0; continue; end\n",
    "            ibucket = min(1 + (length(sent)-1) ÷ d.bucketwidth, length(d.buckets))\n",
    "            bucket = d.buckets[ibucket]\n",
    "            push!(bucket, sent)\n",
    "            if length(bucket) === d.batchsize; break; end\n",
    "        end\n",
    "    end\n",
    "    if bucket === nothing; return nothing; end\n",
    "    batchsize = length(bucket)\n",
    "    maxlen = maximum(length.(bucket))\n",
    "    batch = fill(d.src.vocab.eos, batchsize, maxlen + 1)\n",
    "    for i in 1:batchsize\n",
    "        batch[i, 1:length(bucket[i])] = bucket[i]\n",
    "    end\n",
    "    empty!(bucket)\n",
    "    return batch, state\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mask! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask!\n",
    "function mask!(a,pad)\n",
    "    matr = a\n",
    "    for j in 1:size(matr)[1]\n",
    "        i=0\n",
    "        while i<(length(matr[j,:])-1)\n",
    "            matr[j,length(matr[j,:])-i-1]!=pad && break\n",
    "\n",
    "            if matr[j,length(matr[j,:])-i]== pad\n",
    "                matr[j,length(matr[j,:])-i]= 0\n",
    "            end\n",
    "            i+=1\n",
    "        end\n",
    "    end\n",
    "    matr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed format updated with respect to task\n",
    "struct Embed; w; end\n",
    "\n",
    "function Embed(tagsize::Int, embedsize::Int)\n",
    "    Embed(param(embedsize,tagsize))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    l.w[:,x]\n",
    "end\n",
    "\n",
    "#Linear\n",
    "struct Linear; w; b; end\n",
    "\n",
    "function Linear(inputsize::Int, outputsize::Int)\n",
    "    Linear(param(outputsize,inputsize), param0(outputsize))\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    l.w * mat(x,dims=1) .+ l.b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNsent_model"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct RNNsent_model\n",
    "    embed::Embed        # language embedding\n",
    "    rnn::RNN            # RNN (can be bidirectional)\n",
    "    projection::Linear  # converts output to vocab scores\n",
    "    dropout::Real       # dropout probability to prevent overfitting\n",
    "    vocab::Vocab        # language vocabulary\n",
    "end\n",
    "\n",
    "function RNNsent_model(hidden::Int,      # hidden size for both the encoder and decoder RNN\n",
    "                embsz::Int,          # embedding size\n",
    "                vocab::Vocab;        # language vocabulary\n",
    "                layers=1,            # number of layers\n",
    "                bidirectional=false, # whether encoder RNN is bidirectional\n",
    "                dropout=0)           # dropout probability\n",
    "\n",
    "    embed = Embed(length(vocab.i2w),embsz)\n",
    "\n",
    "    rnn = RNN(embsz,hidden;rnnType=is_lstm_strategy_on ? :lstm : :relu, numLayers=layers,bidirectional=bidirectional, dropout= dropout)\n",
    "    \n",
    "    layerMultiplier = bidirectional ? 2 : 1\n",
    "    \n",
    "    projection = Linear(layerMultiplier*hidden,length(vocab.tags))\n",
    "\n",
    "    RNNsent_model(embed,rnn,projection,dropout,vocab)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calc_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_scores(rm::RNNsent_model, data; average=true)\n",
    "    B, Tx = size(data)\n",
    "    \n",
    "    emb = rm.embed(data)\n",
    "    \n",
    "    y = sum(rm.rnn(emb), dims=3) # nature of nll allows us to sum along each sentence\n",
    "\n",
    "    return rm.projection(reshape(y,:,B))    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_f (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_f(model, batch)  \n",
    "    verify = deepcopy(batch[:,1]) # only tags allowed to in\n",
    "    #mask!(verify,vocab.eos) no need to mask more :)\n",
    "        \n",
    "    scores = calc_scores(model,batch[:,2:end]) # trim one end\n",
    "   \n",
    "    return nll(scores,verify)/size(verify,1) # Loss for each sentence\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maploss (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function maploss(lossfn, model, data)\n",
    "    total_loss = 0.0\n",
    "    for part in collect(data)\n",
    "        total_loss += lossfn(model,part)\n",
    "    end\n",
    "\n",
    "    return total_loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Array{Array{Int64,2},1}:\n",
       " [1 301 … 1 1; 2 6 … 1 1; … ; 1 4 … 1 1; 1 20 … 1 1]         \n",
       " [3 24 … 1 1; 2 59 … 1 1; … ; 1 12 … 1 1; 3 28 … 1 1]        \n",
       " [1 237 … 1 1; 3 660 … 1 1; … ; 1 22 … 1 1; 2 2974 … 1 1]    \n",
       " [1 12 … 1 1; 1 52 … 1 1; … ; 1 16 … 1 1; 2 139 … 1 1]       \n",
       " [1 4 … 1 1; 2 4 … 1 1; … ; 1 317 … 1 1; 3 377 … 1 1]        \n",
       " [1 176 … 1 1; 1 63 … 1 1; … ; 1 22 … 1 1; 2 4 … 1 1]        \n",
       " [2 2168 … 1 1; 1 75 … 1 1; … ; 1 6 … 1 1; 3 2034 … 1 1]     \n",
       " [1 20 … 1 1; 1 4 … 1 1; … ; 1 6 … 1 1; 2 3808 … 1 1]        \n",
       " [1 6 … 1 1; 3 4 … 1 1; … ; 2 12 … 1 1; 2 6257 … 1 1]        \n",
       " [1 6 … 1 1; 1 12 … 1 1; … ; 2 4 … 1 1; 2 2974 … 1 1]        \n",
       " [1 6 … 1 1; 3 69 … 1 1; … ; 1 12 … 1 1; 3 4 … 1 1]          \n",
       " [1 3663 … 1 1; 3 3223 … 1 1; … ; 2 4 … 1 1; 1 634 … 1 1]    \n",
       " [2 738 … 1 1; 1 2961 … 1 1; … ; 2 28 … 1 1; 1 6 … 1 1]      \n",
       " ⋮                                                           \n",
       " [2 1221 … 1 1; 1 2917 … 1 1; … ; 1 5918 … 1 1; 2 6348 … 1 1]\n",
       " [2 37 … 1 1; 1 44 … 1 1; … ; 1 18 … 1 1; 3 7137 … 1 1]      \n",
       " [3 6 … 1 1; 2 22 … 1 1; … ; 2 44 … 1 1; 1 6 … 1 1]          \n",
       " [1 354 … 1 1; 1 12 … 1 1; … ; 2 37 … 1 1; 3 22 … 1 1]       \n",
       " [2 4 … 1 1; 1 218 … 1 1; … ; 4 2568 … 1 1; 1 402 … 1 1]     \n",
       " [1 321 … 1 1; 3 37 … 1 1; … ; 2 6 … 1 1; 1 4 … 1 1]         \n",
       " [1 4 … 1 1; 1 91 … 1 1; … ; 1 4 … 1 1; 1 14 … 1 1]          \n",
       " [2 20 … 1 1; 1 237 … 1 1; … ; 2 1380 … 1 1; 1 925 … 1 1]    \n",
       " [1 168 … 1 1; 1 53 … 1 1; … ; 1 12 … 1 1; 1 62 … 1 1]       \n",
       " [2 757 … 1 1; 2 20 … 1 1; … ; 1 6 … 1 1; 1 75 … 1 1]        \n",
       " [3 2 … 1 1; 1 75 … 1 1; … ; 2 910 … 1 1; 1 1193 … 1 1]      \n",
       " [2 139 … 1 1; 1 6566 … 1 1; … ; 2 10 … 1 1; 1 75 … 1 1]     "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNsent_model(512, 512, vocab; bidirectional=true, dropout=0.2)\n",
    "rm = model\n",
    "\n",
    "train_batches = collect(LMData(train))\n",
    "test_batches = collect(LMData(test))\n",
    "train_batches50 = train_batches[1:50] # Small sample for quick loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RNNsent_model(Embed(P(KnetArray{Float32,2}(512,8218))), LSTM(input=512,hidden=512,bidirectional,dropout=0.2), Linear(P(KnetArray{Float32,2}(5,1024)), P(KnetArray{Float32,1}(5))), 0.2, Vocab(Dict(\"aimlessly\" => 4907,\"offend\" => 3845,\"enjoy\" => 435,\"chocolate\" => 4908,\"fight\" => 1823,\"nicholas\" => 1775,\"everywhere\" => 4593,\"princess\" => 7582,\"uniformly\" => 3846,\"larky\" => 6921…), [\"<s>\", \"<unk>\", \".\", \"the\", \",\", \"a\", \"and\", \"of\", \"to\", \"is\"  …  \"scarifying\", \"sealed\", \"effectiveness\", \"wraps\", \"na\", \"wills\", \"circles\", \"sharper\", \"pluto\", \"pleaser\"], [\"3\", \"4\", \"2\", \"1\", \"0\"], 2, 1, split)), 14.50223196297884)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = adam(loss_f, ((model, batch) for batch in train_batches))\n",
    "bestmodel, bestloss = deepcopy(model), maploss(loss_f, model, test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┣████████████████████┫ [100.00%, 13700/13700, 10:28/10:28, 21.82i/s] (trn = 1.0017202677705728, dev = 3.1460398431870537e9, ∇ = 5.419799f-6)))\n"
     ]
    }
   ],
   "source": [
    "progress!(ncycle(epoch, 100), seconds=5) do x\n",
    "    global bestmodel, bestloss\n",
    "    ## Report gradient norm for the first batch\n",
    "    f = @diff loss_f(model,train_batches[1])\n",
    "    gnorm = sqrt(sum(norm(grad(f,x))^2 for x in params(model)))\n",
    "    ## Report training and validation loss\n",
    "    trnloss = maploss(loss_f,model, train_batches50)\n",
    "    devloss = maploss(loss_f,model, test_batches)\n",
    "    ## Save model that does best on validation data\n",
    "    if devloss < bestloss\n",
    "        bestmodel, bestloss = deepcopy(model), devloss\n",
    "    end\n",
    "    (trn=exp(trnloss), dev=exp(devloss), ∇=gnorm)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
